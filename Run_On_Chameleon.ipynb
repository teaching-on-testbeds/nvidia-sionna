{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NVIDIA Sionna on a Chameleon server\n",
    "\n",
    "[NVIDIA Sionnaâ„¢](https://developer.nvidia.com/sionna) is a GPU-accelerated open-source library for link-level simulations. It enables rapid prototyping of complex communication system architectures and provides native support for the integration of machine learning in 6G signal processing.\n",
    "\n",
    "This notebook will help you get a Sionna container running in a GPU instance on Chameleon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision the resource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chi, os, time, datetime\n",
    "from chi import lease\n",
    "from chi import server\n",
    "from chi import context\n",
    "from chi import hardware\n",
    "\n",
    "username = os.getenv('USER') # all exp resources will have this prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check resource availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will try to reserve a bare metal Ubuntu server with RTX6000 GPU on CHI@UC - pending availability. Before you begin, you should check the host calendar at [https://chi.uc.chameleoncloud.org/project/leases/calendar/host/](https://chi.uc.chameleoncloud.org/project/leases/calendar/host/). In the \"Node Type\" dropdown, filter on `gpu_rtx_6000` and make sure some hosts are available.\n",
    "\n",
    "Alternatively, you can use a different NVIDIA GPU type at CHI@UC or CHI@TACC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chameleon configuration\n",
    "\n",
    "You can change your Chameleon project name (if not using the one that is automatically configured in the JupyterHub environment) and the site on which to reserve resources (depending on availability) in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.version = \"1.0\" # required during transition\n",
    "context.choose_site(default=\"CHI@UC\")\n",
    "context.choose_project()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to change the details of the Chameleon server, e.g. use a different GPU type depending on availability, you can do that in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = \"gpu_rtx_6000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some GPU instance types are:\n",
    "\n",
    "* CHI@UC: `gpu_rtx_6000` (1x RTX6000), `gpu_v100` (4x V100), `compute_gigaio` (1x A100)\n",
    "* CHI@TACC: `compute_liqid` (1x A100), `gpu_p100` (2x P100), `compute_gigaio` (1x A100 or 1x A30 on some nodes, but no GPU on some other nodes)\n",
    "\n",
    "(you can check what is available following the instructions in the next cell.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservation\n",
    "\n",
    "The following cells will create a reservation that begins now, and ends in 8 hours, *if* your requested node type is available.\n",
    "\n",
    "If the node type you have requested is *not* available right now, it will start your reservation as soon as one is available.\n",
    "\n",
    "You can refer to the [CHI@UC host calendar](https://chi.uc.chameleoncloud.org/project/leases/calendar/host/) to see availability (change the \"Node type\" selection to `gpu_rtx_6000`), or refer to the [CHI@TACC host calendar](https://chi.tacc.chameleoncloud.org/project/leases/calendar/host/) to see availability for other node types with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_start_times = [n.next_free_timeslot()[0] for n in hardware.get_nodes(node_type=node_type)]\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(minutes=1)\n",
    "if min(gpu_start_times) > current_time:\n",
    "    lease_start = min(gpu_start_times)\n",
    "    print(f\"There is no {node_type} available now, you can request one starting at {str(lease_start)} (UTC).\")\n",
    "else:\n",
    "    lease_start = current_time\n",
    "    print(f\"A {node_type} IS available now, your lease will start right away.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lease.Lease(f\"sionna-{username}\", duration=datetime.timedelta(hours=8),\n",
    "                start_date = lease_start  )\n",
    "l.add_node_reservation(node_type = node_type, amount = 1) \n",
    "l.add_fip_reservation(1) \n",
    "l.submit(idempotent=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provisioning resources\n",
    "\n",
    "This section provisions resources. It will take approximately 10 minutes. You can check on its status in the Chameleon web-based UI: [https://chi.uc.chameleoncloud.org/project/instances/](https://chi.uc.chameleoncloud.org/project/instances/), then come back here when it is in the READY state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue here, whether using a lease created just now or one created earlier\n",
    "l = lease.get_lease(f\"sionna-{username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = server.Server(\n",
    "    f\"sionna-{username}\", \n",
    "    reservation_id=l.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
    ")\n",
    "s.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate an IP address with this server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_fip = l.get_reserved_floating_ips()[0]\n",
    "s.associate_floating_ip(reserved_fip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and wait for it to come up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.check_connectivity(host=reserved_fip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log in to resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To log in to the resource, use File > New > Terminal in the Chameleon JupyterHub environment, or your local terminal, and paste in the *output* of the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ssh cc@\" + reserved_fip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use common deep learning frameworks like Tensorflow or PyTorch, we can run *containers* that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "node.run(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = ssh.Remote(reserved_fip) # note: need a new SSH session to get new group membership\n",
    "node.run(\"docker run hello-world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NVIDIA container toolkit \n",
    "node.run(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
    "node.run(\"sudo apt update\")\n",
    "node.run(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
    "node.run(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
    "node.run(\"sudo systemctl restart docker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that we can see GPU from inside container\n",
    "node.run(\"docker run --rm --gpus all ubuntu nvidia-smi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Sionna container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"git clone https://github.com/NVlabs/sionna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"cd sionna; make docker\") # this will take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"cd sionna; make run-docker gpus=all\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Sionna container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ssh -L 127.0.0.1:8888:127.0.0.1:8888 cc@' + reserved_fip) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and copy the SSH command that is printed. In a **local terminal on your own laptop**, run the SSH command that is printed by the previous cell. This will set up a tunnel to the Jupyter server that you are running on a Chameleon instance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your Chameleon key is not in the default location, you should also specify the path to your key as an argument, using `-i`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ssh -i ~/.ssh/id_rsa_chameleon -L 127.0.0.1:8888:127.0.0.1:8888 cc@' + reserved_fip) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave this SSH session open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can open the following URL in a browser:\n",
    "\n",
    "http://127.0.0.1:8888/lab\n",
    "\n",
    "and run the example notebooks shown there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release resources\n",
    "\n",
    "If you finish with your experimentation before your lease expires,release your resources and tear down your environment by running the following (commented out to prevent accidental deletions).\n",
    "\n",
    "This section is designed to work as a \"standalone\" portion - you can come back to this notebook, ignore the top part, and just run this section to delete your reasources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment - if you made any changes in the top part, make the same changes here\n",
    "import chi, os\n",
    "from chi import lease, magic, context\n",
    "\n",
    "context.version = \"1.0\" # required during transition\n",
    "\n",
    "context.choose_site(default=\"CHI@UC\")\n",
    "context.choose_project()\n",
    "username = os.getenv('USER') # all exp resources will have this prefix\n",
    "\n",
    "l = lease.get_lease(f\"sionna-{username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-comment to free resources\n",
    "# chi.magic.cleanup_resources(l.id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
